# Ollama_universal_autocomplete
Universal Autocomplete using ollama API

Tested in xubuntu using ollama from tailscale port expose from other pc. Best if use llama 1 7b or 13b because of pure training dataset without any generated AI content post GPT so the result will be more natural.
